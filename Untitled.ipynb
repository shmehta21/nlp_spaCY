{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> NLP using spaCY </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<spacy.lang.en.English at 0x7f81e96d15c0>, spacy.lang.en.English)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp, type(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Text conversion to tokenized object </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tutorial is about Natural Language Processing using spaCY \n",
      "<class 'spacy.tokens.doc.Doc'>\n",
      "['This', 'tutorial', 'is', 'about', 'Natural', 'Language', 'Processing', 'using', 'spaCY']\n"
     ]
    }
   ],
   "source": [
    "sample_text = 'This tutorial is about Natural Language Processing using spaCY '\n",
    "sample_doc = nlp(sample_text)\n",
    "print(sample_doc), print(type(sample_doc))\n",
    "print([token.text for token in sample_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Reading from a file and converting to Doc object </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an introduction to NLP using spaCY.\n",
      "\n",
      "This is an introduction to NLP using spaCY.\n",
      "\n",
      "<class 'spacy.tokens.doc.Doc'>\n",
      "['This', 'is', 'an', 'introduction', 'to', 'NLP', 'using', 'spaCY', '.', '\\n']\n"
     ]
    }
   ],
   "source": [
    "file_text = open('introduction.txt').read()\n",
    "print(file_text)\n",
    "file_doc = nlp(file_text)\n",
    "print(file_doc), print(type(file_doc))\n",
    "print([token.text for token in file_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Sentence Detection which divides a text into linguistically meaningful units \n",
    "using the 'sents' property on doc object</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC is a Python developer currently working with a Fin-techbased in NA. He is interesed in learning Natural Language Processing.\n",
      "Type-><class 'list'>,  Len->2\n",
      "ABC is a Python developer currently working with a Fin-techbased in NA.\n",
      "He is interesed in learning Natural Language Processing.\n"
     ]
    }
   ],
   "source": [
    "sample_text = ('ABC is a Python developer currently'\n",
    "              ' working with a Fin-tech'\n",
    "              'based in NA. He is interesed in learning '\n",
    "              'Natural Language Processing.')\n",
    "print(sample_text)\n",
    "sample_doc  = nlp(sample_text)\n",
    "sentences  = list(sample_doc.sents)\n",
    "print(f'Type->{type(sentences)},  Len->{len(sentences)}')\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using custom boundaries to detect end of a sentence </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XYZ, can you!?never mind i forgot what i was saying.\n",
      "So, do you think we should...?\n"
     ]
    }
   ],
   "source": [
    "def set_custom_boundaries(doc):\n",
    "    ''' Adds support for a custom delimiter to detect end of sentence '''\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == '?':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "custom_delimiter_text = ('XYZ, can you!?'\n",
    "                         'never mind i forgot'\n",
    "                        ' what i was saying. So, do you think'\n",
    "                        ' we should...?')\n",
    "custom_nlp = spacy.load('en_core_web_sm')\n",
    "custom_nlp.add_pipe(set_custom_boundaries,before='parser')\n",
    "custom_doc = custom_nlp(custom_delimiter_text)\n",
    "custom_sentences = list(custom_doc.sents)\n",
    "for sentences in custom_sentences:\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Tokenization with starting index of each word in the sentence </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC 0\n",
      "is 4\n",
      "a 7\n",
      "Python 9\n",
      "developer 16\n",
      "currently 26\n",
      "working 36\n",
      "with 44\n",
      "a 49\n",
      "Fin 51\n",
      "- 54\n",
      "techbased 55\n",
      "in 65\n",
      "NA 68\n",
      ". 70\n",
      "He 72\n",
      "is 75\n",
      "interesed 78\n",
      "in 88\n",
      "learning 91\n",
      "Natural 100\n",
      "Language 108\n",
      "Processing 117\n",
      ". 127\n"
     ]
    }
   ],
   "source": [
    "for token in sample_doc:\n",
    "    print(token, token.idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Various attributes of a token </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Token  Token_Index Token_with_Whitespace  Token_IsAlpha  \\\n",
      "0          ABC            0                  ABC            True   \n",
      "1           is            4                   is            True   \n",
      "2            a            7                    a            True   \n",
      "3       Python            9               Python            True   \n",
      "4    developer           16            developer            True   \n",
      "5    currently           26            currently            True   \n",
      "6      working           36              working            True   \n",
      "7         with           44                 with            True   \n",
      "8            a           49                    a            True   \n",
      "9          Fin           51                   Fin           True   \n",
      "10           -           54                     -          False   \n",
      "11   techbased           55            techbased            True   \n",
      "12          in           65                   in            True   \n",
      "13          NA           68                    NA           True   \n",
      "14           .           70                    .           False   \n",
      "15          He           72                   He            True   \n",
      "16          is           75                   is            True   \n",
      "17   interesed           78            interesed            True   \n",
      "18          in           88                   in            True   \n",
      "19    learning           91             learning            True   \n",
      "20     Natural          100              Natural            True   \n",
      "21    Language          108             Language            True   \n",
      "22  Processing          117            Processing           True   \n",
      "23           .          127                     .          False   \n",
      "\n",
      "    Token_IsPunctuation  Token_IsSpace Token_Shape  Token_IsStop  \n",
      "0                 False          False         XXX         False  \n",
      "1                 False          False          xx          True  \n",
      "2                 False          False           x          True  \n",
      "3                 False          False       Xxxxx         False  \n",
      "4                 False          False        xxxx         False  \n",
      "5                 False          False        xxxx         False  \n",
      "6                 False          False        xxxx         False  \n",
      "7                 False          False        xxxx          True  \n",
      "8                 False          False           x          True  \n",
      "9                 False          False         Xxx         False  \n",
      "10                 True          False           -         False  \n",
      "11                False          False        xxxx         False  \n",
      "12                False          False          xx          True  \n",
      "13                False          False          XX         False  \n",
      "14                 True          False           .         False  \n",
      "15                False          False          Xx          True  \n",
      "16                False          False          xx          True  \n",
      "17                False          False        xxxx         False  \n",
      "18                False          False          xx          True  \n",
      "19                False          False        xxxx         False  \n",
      "20                False          False       Xxxxx         False  \n",
      "21                False          False       Xxxxx         False  \n",
      "22                False          False       Xxxxx         False  \n",
      "23                 True          False           .         False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = []\n",
    "for token in sample_doc:\n",
    "    data.append([token, token.idx, token.text_with_ws, token.is_alpha, token.is_punct, token.is_space,\n",
    "          token.shape_, token.is_stop])\n",
    "df = pd.DataFrame(data, columns=['Token','Token_Index','Token_with_Whitespace','Token_IsAlpha','Token_IsPunctuation','Token_IsSpace','Token_Shape','Token_IsStop'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Lemmatization using spaCY </h4>\n",
    "<h6> Eg:  organizes, organized and organizing are all forms of organize. Here, organize is the lemma. Lemmatization is necessary because it helps you reduce the inflected forms of a word so that they can be analyzed as a single item</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC ABC\n",
      "is be\n",
      "helping help\n",
      "organize organize\n",
      "a a\n",
      "developer developer\n",
      "conference conference\n",
      "on on\n",
      "Applications Applications\n",
      "of of\n",
      "Natural Natural\n",
      "Language Language\n",
      "Processing Processing\n",
      ". .\n",
      "He -PRON-\n",
      "keeps keep\n",
      "organizing organize\n",
      "local local\n",
      "Python Python\n",
      "meetups meetup\n",
      "and and\n",
      "several several\n",
      "internal internal\n",
      "talks talk\n",
      "at at\n",
      "his -PRON-\n",
      "workplace workplace\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "conference_help_text = ('ABC is helping organize a developer'\n",
    "                        ' conference on Applications of Natural Language'\n",
    "                        ' Processing. He keeps organizing local Python meetups'\n",
    "                        ' and several internal talks at his workplace.')\n",
    "conference_help_doc = nlp(conference_help_text)\n",
    "for token in conference_help_doc:\n",
    "    print(token, token.lemma_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Word Frequency </h4>\n",
    "<h6> Find out unique and most common/repeating words in a sentence/paragraph </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most common words-->[('ABC', 3), ('Natural', 3), ('Language', 3), ('Processing', 3), ('Piano', 3)]\n",
      "Unique words-->['XYZ', 'currentlyworking', 'based', 'company', 'interested', 'conference', 'happening', '21', 'July', '2019', 'titled', 'Applications', 'helpline', 'number', 'available', '+1', '1234567891', 'helping', 'organize', 'keeps', 'organizing', 'local', 'meetups', 'internal', 'talks', 'workplace', 'Gus', 'presenting', 'introduce', 'reader', 'Use', 'cases', 'Apart', 'work', 'passionate', 'music', 'play', 'enrolled', 'weekend', 'batch', 'situated', 'Mayfair', 'City', 'world', 'class', 'piano', 'instructors']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "complete_text = ('ABC XYZ is a Python developer currently'\n",
    "     'working for a US-based Fintech company. He is'\n",
    "     ' interested in learning Natural Language Processing.'\n",
    "     ' There is a developer conference happening on 21 July'\n",
    "     ' 2019 in London. It is titled \"Applications of Natural'\n",
    "     ' Language Processing\". There is a helpline number '\n",
    "     ' available at +1-1234567891. ABC is helping organize it.'\n",
    "     ' He keeps organizing local Python meetups and several'\n",
    "     ' internal talks at his workplace. Gus is also presenting'\n",
    "     ' a talk. The talk will introduce the reader about \"Use'\n",
    "     ' cases of Natural Language Processing in Fintech\".'\n",
    "     ' Apart from his work, he is very passionate about music.'\n",
    "     ' ABC is learning to play the Piano. He has enrolled '\n",
    "     ' himself in the weekend batch of Great Piano Academy.'\n",
    "     ' Great Piano Academy is situated in Mayfair or the City'\n",
    "     ' of London and has world-class piano instructors.')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "complete_doc = nlp(complete_text)\n",
    "#Remove stop words and punctuations\n",
    "words = [token.text for token in complete_doc \n",
    "            if not token.is_stop and not token.is_punct]\n",
    "word_frequency = Counter(words)\n",
    "most_common_words = word_frequency.most_common(5)\n",
    "print(f'5 most common words-->{most_common_words}')\n",
    "unique_words = [word for word,freq in word_frequency.items() if freq==1]\n",
    "print(f'Unique words-->{unique_words}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Parts of speech tagging</h4>\n",
    "<h6>More explanation <a href=\"https://spacy.io/api/annotation#pos-tagging\">here</a></h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC NNP PROPN noun, proper singular\n",
      "is VBZ VERB verb, 3rd person singular present\n",
      "a DT DET determiner\n",
      "Python NNP PROPN noun, proper singular\n",
      "developer NN NOUN noun, singular or mass\n",
      "currently RB ADV adverb\n",
      "working VBG VERB verb, gerund or present participle\n",
      "with IN ADP conjunction, subordinating or preposition\n",
      "a DT DET determiner\n",
      "Fin NNP PROPN noun, proper singular\n",
      "- HYPH PUNCT punctuation mark, hyphen\n",
      "techbased VBN VERB verb, past participle\n",
      "in IN ADP conjunction, subordinating or preposition\n",
      "NA NNP PROPN noun, proper singular\n",
      ". . PUNCT punctuation mark, sentence closer\n",
      "He PRP PRON pronoun, personal\n",
      "is VBZ VERB verb, 3rd person singular present\n",
      "interesed VBN VERB verb, past participle\n",
      "in IN ADP conjunction, subordinating or preposition\n",
      "learning VBG VERB verb, gerund or present participle\n",
      "Natural NNP PROPN noun, proper singular\n",
      "Language NNP PROPN noun, proper singular\n",
      "Processing NNP PROPN noun, proper singular\n",
      ". . PUNCT punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "for token in sample_doc:\n",
    "    print( token, token.tag_, token.pos_, spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using displaCy</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"276a726510d445e5b9fe515d81b99462-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">He</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">interested</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Natural</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Processing.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-276a726510d445e5b9fe515d81b99462-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-276a726510d445e5b9fe515d81b99462-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-276a726510d445e5b9fe515d81b99462-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-276a726510d445e5b9fe515d81b99462-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-276a726510d445e5b9fe515d81b99462-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-276a726510d445e5b9fe515d81b99462-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-276a726510d445e5b9fe515d81b99462-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-276a726510d445e5b9fe515d81b99462-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-276a726510d445e5b9fe515d81b99462-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-276a726510d445e5b9fe515d81b99462-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-276a726510d445e5b9fe515d81b99462-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-276a726510d445e5b9fe515d81b99462-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-276a726510d445e5b9fe515d81b99462-0-6\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-276a726510d445e5b9fe515d81b99462-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interest_text = 'He is interested in learning Natural Language Processing.'\n",
    "interest_doc = nlp(interest_text)\n",
    "from spacy import displacy\n",
    "#displacy.serve(interest_doc,style='dep'). This will run a local web server and a visualisation will appear locally on localhost:5000\n",
    "displacy.render(interest_doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Rule based matching using spaCY </h4>\n",
    "  <ul> \n",
    "  <li>Extract first and last names from a sentence(s)</li>\n",
    "  <li> Extract phone nos from a sentence(s)</li>\n",
    "  </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABC XYZ'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher =  Matcher(nlp.vocab)\n",
    "def extract_full_name(nlp_doc):\n",
    "    pattern = [{'POS':'PROPN'}, {'POS':'PROPN'}]#pattern defines 2 POS(part of speech) tags for which the tokens should be a PROPER NOUN\n",
    "    matcher.add('FULL_NAME',None,pattern)#add method takes as input an ID Key(could be any ID key), callback function and matching pattern as input\n",
    "    matches = matcher(nlp_doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        return span.text\n",
    "\n",
    "extract_full_name(complete_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(123) 456-789'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "conference_org_text = ('There is a developer conference'\n",
    "    ' happening on 21 July 2019 in London. It is titled'\n",
    "     ' \"Applications of Natural Language Processing\".'\n",
    "     ' There is a helpline number available'\n",
    "     ' at (123) 456-789')\n",
    "\n",
    "#ORTH -> Gives the exact text of the token\n",
    "#SHAPE -> Transforms the token string to orthographic features\n",
    "#OP -> defines operators. Using ? as a value means that the pattern is optional, meaning it can match 0 or 1 times.\n",
    "def extract_phone_number(nlp_doc):\n",
    "    pattern = [{'ORTH':'('},{'SHAPE':'ddd'},{'ORTH':')'},{'SHAPE':'ddd'},{'ORTH':'-', 'OP':'?'},{'SHAPE':'ddd'}]\n",
    "    matcher.add('PHONE NUMBER', None, pattern)\n",
    "    matches = matcher(nlp_doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        return span.text\n",
    "    \n",
    "conference_org_doc = nlp(conference_org_text)\n",
    "extract_phone_number(conference_org_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b1f9defe0a064f1b8eb235a03c27c60e-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">ABC</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">learning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">piano</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1f9defe0a064f1b8eb235a03c27c60e-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1f9defe0a064f1b8eb235a03c27c60e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1f9defe0a064f1b8eb235a03c27c60e-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1f9defe0a064f1b8eb235a03c27c60e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b1f9defe0a064f1b8eb235a03c27c60e-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b1f9defe0a064f1b8eb235a03c27c60e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "plain_text = \"ABC is learning piano\"\n",
    "plain_doc = nlp(plain_text)\n",
    "displacy.render(plain_doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Named-Entity Recognition </h4>\n",
    "<h5> the process of classifying unstructured text into pre-defined categories, such as person names, organizations, locations, monetary values, percentages, time expressions, and so on </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Text    Label                            Explain_Label\n",
      "0  Harmony Piano Academy      ORG  Companies, agencies, institutions, etc.\n",
      "1                 Mumbai      GPE                Countries, cities, states\n",
      "2     the City of Dreams      GPE                Countries, cities, states\n",
      "3             around $10    MONEY          Monetary values, including unit\n",
      "4               09:30 am     TIME                 Times smaller than a day\n",
      "5         Monday morning     TIME                 Times smaller than a day\n",
      "6          less than 20%  PERCENT                Percentage, including \"%\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "piano_class_info_text = ('Harmony Piano Academy is situated'\n",
    "                         ' in Mumbai or the City of Dreams'\n",
    "                         ' and has world class piano instructors.'\n",
    "                         'Mr. Fernandes is our head-instructor there and he charges around $10 for each session.'\n",
    "                         ' The classes will start at sharp 09:30 am on Monday morning.'\n",
    "                         ' The chances of you reaching on time due to heavy traffic is less than 20%')\n",
    "piano_class_info_doc = nlp(piano_class_info_text)\n",
    "cols = ['Text','Label','Explain_Label']\n",
    "rows = []\n",
    "#spaCY has the property \"ents\" which can be used to extract named entities\n",
    "for entry in piano_class_info_doc.ents:\n",
    "    rows.append([entry.text, entry.label_, spacy.explain(entry.label_)])\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "print(df)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
